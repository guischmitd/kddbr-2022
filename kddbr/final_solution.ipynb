{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from context import DATADIR, RAWDATADIR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "data = pd.read_csv(RAWDATADIR / 'public.csv').set_index('Filename')\n",
    "train = data[~data['North'].isna()]\n",
    "test = data[data['North'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import ImageFeatureExtractor\n",
    "\n",
    "FORCE_RUN = False\n",
    "\n",
    "if (DATADIR / 'feats/feats.parquet').exists() and not FORCE_RUN:\n",
    "    feats = pd.read_parquet(DATADIR / 'feats/feats.parquet')\n",
    "\n",
    "else:\n",
    "    feat_extractor = ImageFeatureExtractor()\n",
    "    feats = data.progress_apply(feat_extractor.get_features_from_row, axis=1)\n",
    "\n",
    "    feats.to_parquet(DATADIR / 'feats/feats.parquet')\n",
    "\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine order of clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from order_images import order_from_df\n",
    "\n",
    "FORCE_RUN = False\n",
    "\n",
    "if (DATADIR / 'processed/train_ordered.parquet').exists() and not FORCE_RUN:\n",
    "    train_ordered = pd.read_parquet(DATADIR / 'processed/train_ordered.parquet')\n",
    "    test_ordered = pd.read_parquet(DATADIR / 'processed/test_ordered.parquet')\n",
    "\n",
    "else:\n",
    "    train_ordered = order_from_df(train, plot=False)\n",
    "    test_ordered = order_from_df(test, plot=False)\n",
    "\n",
    "    train_ordered.to_parquet(DATADIR / 'processed/train_ordered.parquet')\n",
    "    test_ordered.to_parquet(DATADIR / 'processed/test_ordered.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lag/leap features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import add_lags\n",
    "\n",
    "n_lags = 7\n",
    "\n",
    "train_feats = add_lags(train_ordered.join(feats), n_lags=n_lags)\n",
    "test_feats = add_lags(test_ordered.join(feats), n_lags=n_lags)\n",
    "\n",
    "test_feats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import build_model, get_Xy_cols\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "PERFORM_CV = True\n",
    "\n",
    "if PERFORM_CV:\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "\n",
    "    cv_scores = []\n",
    "    oof_preds = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(train_feats, groups=train_feats['sequence'])):\n",
    "        print(f'Fitting fold {i}...')\n",
    "        model = build_model()\n",
    "        predictors, targets = get_Xy_cols(train_feats)\n",
    "        \n",
    "        X_train, X_test = train_feats.iloc[train_idx][predictors].copy(), train_feats.iloc[test_idx][predictors].copy()\n",
    "        \n",
    "        # Check for leaks between train/test sequences\n",
    "        sequence_leak = set(train_feats.iloc[train_idx]['sequence']).intersection(set(train_feats.iloc[test_idx]['sequence']))\n",
    "        assert len(sequence_leak) == 0, f'Sequence leakeage found in train/test sets: {sequence_leak}'\n",
    "\n",
    "        y_train, y_test = train_feats.loc[X_train.index, targets], train_feats.loc[X_test.index, targets]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        oof_preds.append(pd.DataFrame(y_pred, index=X_test.index, columns=['North', 'East']))\n",
    "        cv_scores.append(mean_squared_error(y_test, model.predict(X_test), squared=False))\n",
    "        print(cv_scores)\n",
    "    \n",
    "    print(f'CV{len(cv_scores)}=', cv_scores)\n",
    "    print(np.mean(cv_scores), 'Â±', np.std(cv_scores))\n",
    "    \n",
    "model = build_model()\n",
    "predictors, targets = get_Xy_cols(train_feats)\n",
    "model.fit(train_feats[predictors], train_feats[targets])\n",
    "\n",
    "joblib.dump(model, DATADIR / f'models/{datetime.now().strftime(\"%Y%m%d_%H%M%S_model.joblib\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import generate_submission_files\n",
    "\n",
    "FORCE_RUN = False\n",
    "\n",
    "model_paths = list((DATADIR / 'models').glob('*.joblib'))\n",
    "if len(model_paths) > 0:\n",
    "    print(f'Found {len(model_paths)} in models dir. Performing predictions...')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        sub_path = DATADIR / 'subs' / ('_'.join(mp.stem.split('_')[:2]) + '_sub.csv')\n",
    "        \n",
    "        if sub_path.exists() and not FORCE_RUN:\n",
    "            continue\n",
    "        else:\n",
    "            print(f'Generating prediction file for model {mp}')\n",
    "            preds = generate_submission_files(mp, test_feats[predictors])\n",
    "            preds.to_csv(sub_path)\n",
    "\n",
    "else:\n",
    "    raise FileNotFoundError(f'No models found in {DATADIR / \"models\"}. Have any models been fitted yet?')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b911d7ab9a36efbc330bc9011e457dd85ab540942d701223e32fa2454f364ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
